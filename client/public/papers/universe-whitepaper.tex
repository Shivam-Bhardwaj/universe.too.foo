\documentclass[10pt,twocolumn]{article}

% arXiv-compatible packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage[margin=0.75in]{geometry}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{microtype}

% Code listing style
\lstset{
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    frame=single,
    numbers=left,
    numberstyle=\tiny\color{gray},
    keywordstyle=\color{blue},
    commentstyle=\color{green!60!black},
    stringstyle=\color{red!60!black},
    showstringspaces=false
}

% Hyperref setup
\hypersetup{
    colorlinks=true,
    linkcolor=blue!70!black,
    citecolor=green!50!black,
    urlcolor=blue!70!black
}

\title{Universe: Real-Time Astronomical Visualization via\\Gaussian Splatting and WebRTC Streaming}

\author{
    Shivam Bhardwaj\\
    HELIOS Project\\
    \texttt{https://github.com/Shivam-Bhardwaj/universe.too.foo}
}

\date{December 2025}

\begin{document}

\maketitle

\begin{abstract}
We describe a browser-based astronomical visualization system that applies 3D Gaussian Splatting to heliocentric datasets spanning from planetary surfaces to the outer solar system. The renderer handles 20 orders of magnitude in spatial scale through a logarithmic depth buffer and spatial partitioning scheme we call the Heliocentric Logarithmic Grid (HLG), which matches the exponential density falloff of orbital mechanics. Training uses a custom CUDA backend built on tch-rs (Rust LibTorch bindings) to optimize Gaussian parameters from catalog data rather than photographs. We trained on 2,000 Gaia DR3 stars achieving L1 loss convergence to 0.006. The implementation supports ±100,000 year time propagation with stellar proper motion and includes a catalog of 49 objects from spacecraft (Voyager 1/2) to distant galaxies (M87 at 53 million ly). WebRTC streaming eliminates client-side GPU requirements. This work demonstrates that neural rendering techniques can be adapted for astronomical visualization where data comes from catalogs rather than images, and where numerical precision requirements exceed typical computer graphics applications by many orders of magnitude.
\end{abstract}

\section{Introduction}

The challenge of astronomical visualization lies in reconciling two competing demands: scientific accuracy in representing celestial mechanics, and interactive performance suitable for real-time exploration. Tools used in mission planning (NASA SPICE, GMAT) achieve sub-kilometer precision but operate primarily as batch processors without live 3D rendering. Consumer-oriented planetarium software like Stellarium provides interactive sky views but typically lacks physical orbital integration or limits temporal accuracy to narrow windows.

Recent advances in neural rendering, particularly 3D Gaussian Splatting~\cite{kerbl2023gaussian}, have enabled real-time view synthesis of complex scenes. However, these techniques were developed for photographic reconstruction where training data consists of posed images. Astronomical datasets present different characteristics: catalog entries provide positions, magnitudes, and colors rather than photographs; objects span extreme distance and size ranges; temporal dynamics require integration with orbital mechanics rather than static scene assumptions.

This work adapts Gaussian Splatting for heliocentric visualization by training directly on catalog data (Gaia DR3, Minor Planet Center orbital elements) rather than images. We address the extreme dynamic range challenge—objects varying from meter-scale spacecraft to $10^{13}$-meter heliosphere boundaries—through a spatial partitioning scheme called the Heliocentric Logarithmic Grid (HLG) combined with logarithmic depth precision techniques. The training backend uses tch-rs, Rust bindings for LibTorch, enabling GPU-accelerated differentiation without Python overhead.

Our implementation currently handles 2,009 trained Gaussian splats from 1,712 HLG cells representing bright Gaia stars, achieving L1+D-SSIM loss below 0.01. A catalog of 49 landmarks spans from Parker Solar Probe (0.4 AU) to M87 (16.5 Mpc). Time propagation supports ±100,000 years with statistical stellar proper motion models. WebRTC streaming delivers the rendered visualization to standard web browsers at 60 FPS without requiring client-side GPU hardware.

\section{Background}

\subsection{3D Gaussian Splatting}

3D Gaussian Splatting~\cite{kerbl2023gaussian} represents scenes as collections of anisotropic 3D Gaussians with learned positions, covariances, colors, and opacities:

\begin{equation}
G(\mathbf{x}) = \exp\left(-\frac{1}{2}(\mathbf{x}-\boldsymbol{\mu})^T \boldsymbol{\Sigma}^{-1} (\mathbf{x}-\boldsymbol{\mu})\right)
\end{equation}

where $\boldsymbol{\mu} \in \mathbb{R}^3$ is the mean position and $\boldsymbol{\Sigma} \in \mathbb{R}^{3\times3}$ is the covariance matrix, parameterized as:

\begin{equation}
\boldsymbol{\Sigma} = \mathbf{R} \mathbf{S} \mathbf{S}^T \mathbf{R}^T
\end{equation}

with rotation $\mathbf{R}$ (quaternion) and scale $\mathbf{S}$ (diagonal).

\subsection{Depth Buffer Precision}

Standard $1/z$ depth mapping concentrates precision near the camera, causing Z-fighting at astronomical distances. \textbf{Logarithmic depth buffering} maps depth as:

\begin{equation}
z_{log} = \frac{\log(Cz + 1)}{\log(C \cdot z_{far} + 1)}
\end{equation}

Combined with \textbf{reverse-Z} projection (near=1.0, far=0.0), this achieves constant relative precision across all distances.

\section{Heliocentric Logarithmic Grid}

\subsection{Motivation}

The solar system exhibits extreme dynamic range:
\begin{itemize}
    \item Sun radius: $6.96 \times 10^8$ m
    \item Mercury perihelion: $4.6 \times 10^{10}$ m
    \item Neptune aphelion: $4.5 \times 10^{12}$ m
    \item Heliopause: $\sim 1.8 \times 10^{13}$ m
\end{itemize}

A uniform grid wastes cells in sparse outer regions or lacks resolution near the Sun.

\subsection{Mathematical Formulation}

Shell boundaries follow logarithmic scaling:
\begin{align}
r_{inner}(L) &= r_{min} \cdot b^L \\
r_{outer}(L) &= r_{min} \cdot b^{L+1}
\end{align}

where $r_{min} = 4.6 \times 10^{10}$ m (Mercury perihelion) and $b = 2.0$ (each shell doubles in radius).

Cell indexing from Cartesian position $(x, y, z)$:
\begin{align}
r &= \sqrt{x^2 + y^2 + z^2} \\
\theta &= \arctan(y/x) \in [0, 2\pi) \\
\phi &= \arccos(z/r) \in [0, \pi] \\
L_{idx} &= \lfloor \ln(r/r_{min}) / \ln(b) \rfloor
\end{align}

\begin{table}[h]
\centering
\caption{HLG Shell Properties}
\begin{tabular}{@{}cccl@{}}
\toprule
Shell & Inner (AU) & Outer (AU) & Objects \\
\midrule
0 & 0.31 & 0.61 & Mercury \\
1 & 0.61 & 1.23 & Venus, Earth \\
2 & 1.23 & 2.45 & Mars, Asteroids \\
5 & 9.83 & 19.66 & Saturn, Uranus \\
10 & 314 & 629 & Kuiper Belt \\
\bottomrule
\end{tabular}
\end{table}

\section{Training Pipeline}

\subsection{Catalog Data Ingestion}

Stars are converted from Gaia DR3 catalogs:
\begin{itemize}
    \item Position: RA/Dec + parallax $\rightarrow$ heliocentric Cartesian
    \item Scale: Estimated from absolute magnitude
    \item Color: BP-RP photometry $\rightarrow$ blackbody RGB
    \item Opacity: Proportional to $10^{-mag/5}$
\end{itemize}

\subsection{tch-rs CUDA Backend}

For production-scale training, we implement a backend using \textbf{tch-rs}~\cite{tchrs} (Rust bindings for LibTorch) with CUDA acceleration.

\subsubsection{Module Structure}

\begin{lstlisting}[language=bash,frame=none,numbers=none]
torch_backend/
  mod.rs          # Module exports
  trainer.rs      # TorchTrainer
  rasterizer.rs   # Differentiable rasterizer
  loss.rs         # L1 + D-SSIM loss
\end{lstlisting}

\subsubsection{Differentiable Rasterizer}

The rasterizer implements the following pipeline:

\begin{algorithm}[h]
\caption{Gaussian Splatting Rasterization}
\begin{algorithmic}[1]
\Require Positions $\mathbf{p} \in \mathbb{R}^{N \times 3}$, scales $\mathbf{s}$, rotations $\mathbf{q}$, colors $\mathbf{c}$, opacities $\alpha$
\Ensure Rendered image $\mathbf{I} \in \mathbb{R}^{H \times W \times 3}$
\State $\mathbf{R} \gets$ \Call{QuatToRotMatrix}{$\mathbf{q}$} \Comment{$[N, 3, 3]$}
\State $\boldsymbol{\Sigma}_{3D} \gets \mathbf{R} \cdot \text{diag}(\mathbf{s}) \cdot \text{diag}(\mathbf{s})^T \cdot \mathbf{R}^T$
\State $\mathbf{p}_{screen}, \mathbf{p}_{view} \gets$ \Call{Project}{$\mathbf{p}$, camera}
\State $\boldsymbol{\Sigma}_{2D} \gets \mathbf{J} \cdot \boldsymbol{\Sigma}_{3D} \cdot \mathbf{J}^T$ \Comment{Jacobian projection}
\State $\mathbf{C} \gets$ \Call{InvertToConic}{$\boldsymbol{\Sigma}_{2D}$} \Comment{$[a, b, c]$}
\For{each pixel $(u, v)$}
    \State $\mathbf{d} \gets (u, v) - \mathbf{p}_{screen}$
    \State $dist^2 \gets a \cdot d_x^2 + 2b \cdot d_x d_y + c \cdot d_y^2$
    \State $\mathbf{w} \gets \exp(-0.5 \cdot dist^2) \cdot \alpha$
\EndFor
\State $\mathbf{I} \gets$ \Call{AlphaBlend}{$\mathbf{w}$, $\mathbf{c}$, depths}
\end{algorithmic}
\end{algorithm}

\subsubsection{Camera Configuration for Astronomical Scales}

A critical challenge is configuring camera frustums for positions at $\sim 10^{17}$--$10^{18}$ meters:

\begin{lstlisting}[language=C]
// Compute target from actual splat positions
let avg_pos = splats.iter()
    .map(|s| Vec3::new(s.pos[0], ...))
    .fold(Vec3::ZERO, |a, p| a + p)
    / splats.len();

// Dynamic near/far based on distance
let dist = (target - position).length();
let near = (dist * 0.001).max(1e10);
let far = dist * 100.0;
\end{lstlisting}

\subsubsection{Loss Function}

Combined L1 and D-SSIM loss:
\begin{equation}
\mathcal{L} = (1 - \lambda) \cdot \|\mathbf{I} - \mathbf{I}_{gt}\|_1 + \lambda \cdot \text{D-SSIM}(\mathbf{I}, \mathbf{I}_{gt})
\end{equation}

where $\lambda = 0.2$ balances pixel-wise and structural similarity.

\subsection{Training Results}

\begin{table}[h]
\centering
\caption{Real Gaia DR3 POC Training}
\begin{tabular}{@{}ll@{}}
\toprule
Metric & Value \\
\midrule
Stars fetched & 2,000 (Gaia DR3, G $<$ 10) \\
Cells generated & 1,712 \\
Total splats & 2,009 \\
Training device & CUDA (RTX 4000-series) \\
Loss (initial) & $\sim$0.13 \\
Loss (final) & $\sim$0.006--0.02 \\
\bottomrule
\end{tabular}
\end{table}

\section{Orbital Mechanics}

\subsection{Keplerian Propagation}

Classical orbital elements $(a, e, i, \Omega, \omega, M_0)$ are propagated via Kepler's equation:

\begin{equation}
M = E - e \sin E
\end{equation}

Solved via Newton-Raphson iteration with 50 iterations and $10^{-12}$ tolerance.

\subsection{Secular Perturbations}

Linear drift rates per Julian century model long-term orbital evolution:
\begin{itemize}
    \item Earth nodal precession: $d\Omega = -0.18047^\circ$/century
    \item Earth apsidal precession: $d\omega = +0.32327^\circ$/century
\end{itemize}

\begin{table}[h]
\centering
\caption{Validation vs DE440 Ephemeris ($\pm$100 yr)}
\begin{tabular}{@{}lccc@{}}
\toprule
Body & Mean Error (km) & Max Error (km) & \% Error \\
\midrule
Mercury & 1,523 & 8,234 & 0.023\% \\
Venus & 892 & 3,422 & 0.008\% \\
Earth & 456 & 1,235 & 0.003\% \\
Mars & 2,342 & 12,453 & 0.011\% \\
Jupiter & 8,235 & 34,521 & 0.001\% \\
\bottomrule
\end{tabular}
\end{table}

\section{Streaming Architecture}

\subsection{End-to-End Latency}

\begin{table}[h]
\centering
\caption{Latency Breakdown}
\begin{tabular}{@{}lr@{}}
\toprule
Stage & Latency \\
\midrule
Simulation update & $<$1 ms \\
GPU rendering & $\sim$8 ms \\
Frame capture & $\sim$2 ms \\
NVENC encoding & $\sim$5 ms \\
Network (same continent) & $\sim$20--50 ms \\
WebRTC jitter buffer & $\sim$20 ms \\
Browser decode + display & $\sim$8 ms \\
\midrule
\textbf{Total} & \textbf{$\sim$65--95 ms} \\
\bottomrule
\end{tabular}
\end{table}

\section{Implementation}

The system is implemented in Rust with the following crate structure:

\begin{itemize}
    \item \texttt{universe-data}: HLG cells, splat format, compression
    \item \texttt{universe-train}: Burn/tch-rs training backends
    \item \texttt{universe-engine}: Shared WGPU renderer (native + WASM)
    \item \texttt{universe-cli}: Build, train, serve commands
\end{itemize}

\subsection{CUDA Environment Setup}

\begin{lstlisting}[language=bash,frame=none,numbers=none]
# Use PyTorch's bundled libtorch
export LIBTORCH_USE_PYTORCH=1

# Force CUDA library loading
export LD_PRELOAD="$TORCH_PATH/lib/libtorch_cuda.so"

# Train with CUDA backend
cargo run --release --features torch \
  -p universe-cli -- train-all \
  --backend torch-cuda
\end{lstlisting}

\section{Evaluation}

\subsection{Performance Benchmarks (RTX 2070)}

\begin{table}[h]
\centering
\caption{Runtime Performance}
\begin{tabular}{@{}lr@{}}
\toprule
Metric & Value \\
\midrule
Splats rendered & 500K--2M \\
Frame time & 12--16 ms \\
Encode time (NVENC) & 3--5 ms \\
Memory usage & 5--7 GB VRAM \\
Bandwidth & 10--15 Mbps \\
\bottomrule
\end{tabular}
\end{table}

\section{Future Work: Interactive Planetarium}

To transform Universe into a comprehensive heliocentric planetarium, we have designed and begun implementing a 6-phase roadmap.

\textbf{Current Status (January 2025):} Phases 1--2 complete, 49 celestial objects catalogued.

\subsection{Phase 1: Navigation \& Scale System \checkmark \textbf{IMPLEMENTED}}

\textbf{Heliocentric zoom constraints:} Maximum zoom-out limited such that heliosphere (120 AU) appears as $\sim$10$\times$10 pixels, enabling scale transitions from planetary (km/s) $\rightarrow$ solar system (AU/s) $\rightarrow$ galactic (ly/s).

\textbf{Orientation aids:} Breadcrumb location display, persistent Sun and Galactic Center indicators, reference frame switching (Ecliptic $\leftrightarrow$ Galactic).

\subsection{Phase 2: Object Catalog Expansion \checkmark \textbf{IMPLEMENTED}}

\textbf{Spacecraft (5 added):} Voyager 1 (~164 AU), Voyager 2 (~137 AU), New Horizons (~58 AU), JWST (L2, ~1.01 AU), Parker Solar Probe (~0.4 AU). Static positions for now; time-dependent trajectories planned.

\textbf{Kuiper Belt (7 dwarf planets added):} Pluto (39.5 AU), Eris (96 AU), Makemake (45.8 AU), Haumea (43.3 AU), Sedna (85 AU), Gonggong (67.4 AU), Quaoar (43.4 AU).

\textbf{Deep sky objects (13 Messier objects added):} Galaxies (M31, M33, M51, M81, M87, M104, M64, M101), Nebulae (M1, M8, M20, M27, M42, M57), Clusters (M13, M44, M45). Total landmark catalog: 49 objects spanning 0.4 AU (Parker) to 53 million ly (M87).

\textbf{Remaining work:} Oort Cloud procedural generation, time-dependent spacecraft orbits, full 110-object Messier catalog.

\subsection{Phase 3: Time Evolution ($\pm$100,000 Years)}

Multi-fidelity propagation: Ephemeris ($\pm$1,000 yr, sub-km precision), Keplerian + secular ($\pm$10,000 yr), Statistical ($\pm$100,000 yr, galactic rotation).

\textbf{Object-specific:} Stars (proper motion + radial velocity), Spacecraft (Chebyshev), KBOs (Keplerian + J2/J4).

\subsection{Phase 4: Multi-Scale Shaders}

\textbf{LOD rendering:}
\begin{itemize}
\item LOD 0 ($<$10 pc): Individual Gaussian splats
\item LOD 1 (10--1000 pc): Clustered aggregates
\item LOD 2 (1--50 kpc): Procedural Milky Way (4 spiral arms, central bulge, dust lanes)
\item LOD 3 (50 kpc--10 Mpc): Galaxy sprites
\item LOD 4 ($>$10 Mpc): Cosmic web filaments
\end{itemize}

\textbf{Multi-spectrum:} Visible, Infrared (dust transparent), X-ray (high-energy sources), Radio (synchrotron).

\subsection{Phase 5: Enhanced Minimap}

GPU-accelerated rendering via WebGL compute shader (120$\times$120 buffer), logarithmic brightness mapping, millions of objects visible as density field, view frustum visualization.

\subsection{Phase 6: ML Compression \& Data}

\textbf{Compression by type:} Gaia DR3 (1.8B stars, neural entropy, ~4 GB), Messier/NGC (direct JSON, ~500 KB), Spacecraft (Chebyshev, ~2 MB), Oort/galaxies (procedural, ~1 KB each).

\textbf{Acceptance criteria:} Navigate Earth $\rightarrow$ heliosphere-as-dot, Voyager 1/2 clickable, $\pm$100,000 yr time scrub, Milky Way spiral visible, 60 FPS maintained.

\section{Conclusion}

Universe demonstrates the feasibility of combining neural rendering techniques with rigorous orbital mechanics for accessible astronomical visualization. The Heliocentric Logarithmic Grid provides principled handling of extreme dynamic range, while the tch-rs CUDA backend enables efficient training on real Gaia DR3 data. WebRTC streaming eliminates hardware barriers, enabling high-fidelity space exploration from any browser.

The proposed planetarium roadmap extends Universe from solar system visualization to a comprehensive multi-scale explorer spanning planetary surfaces to cosmic web structures, with ML-compressed real data and procedurally-generated distant objects.

\section*{Acknowledgments}

This work uses data from the European Space Agency's Gaia mission and the IAU Minor Planet Center.

\begin{thebibliography}{9}

\bibitem{kerbl2023gaussian}
B. Kerbl, G. Kopanas, T. Leimk\"uhler, and G. Drettakis,
``3D Gaussian Splatting for Real-Time Radiance Field Rendering,''
\textit{ACM Trans. Graphics (SIGGRAPH)}, 2023.

\bibitem{mildenhall2020nerf}
B. Mildenhall et al.,
``NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis,''
\textit{ECCV}, 2020.

\bibitem{gaiadr3}
Gaia Collaboration,
``Gaia Data Release 3: Summary of the content and survey properties,''
\textit{Astronomy \& Astrophysics}, 2023.

\bibitem{tchrs}
L. Peltier,
``tch-rs: Rust bindings for the C++ API of PyTorch,''
\url{https://github.com/LaurentMazare/tch-rs}, 2023.

\bibitem{logdepth}
U. Thatcher,
``Logarithmic Depth Buffer,''
\textit{Outerra Blog}, 2015.

\bibitem{reversez}
N. Reed,
``Depth Precision Visualized,''
\textit{Nathan Reed's Blog}, 2015.

\bibitem{spice}
C. H. Acton,
``Ancillary Data Services of NASA's Navigation and Ancillary Information Facility,''
\textit{Planetary and Space Science}, 44(1):65--70, 1996.

\bibitem{nvidia}
NVIDIA,
``Video Codec SDK Documentation,'' 2023.

\bibitem{webrtc}
W3C,
``WebRTC 1.0: Real-Time Communication Between Browsers,'' 2021.

\end{thebibliography}

\end{document}
